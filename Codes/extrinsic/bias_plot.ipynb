{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_to_plot = ['waiter',  'landlord',   'salesman','policeman',\n",
    "                   'monk',   'handyman' , 'congressman', 'headmaster']\n",
    "n_to_plot = ['socialite', 'homemaker', 'housekeeper', 'nurse', 'nanny',\n",
    "                     'hooker', 'marshal', 'archbishop', 'captain', 'colonel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_bias(E, gender_direction, ll, \\\n",
    "              m_to_plot = m_to_plot, n_to_plot = n_to_plot, \\\n",
    "              female_stereotyped_prof = female_stereotyped_prof, male_stereotyped_prof = male_stereotyped_prof, neutral_prof = neutral_prof):\n",
    "    female_stereotyped_gender = {x: np.dot(E.v(x), gender_direction) \\\n",
    "                                 for x in female_stereotyped_prof if x in E.words}\n",
    "    male_stereotyped_gender = {x: np.dot(E.v(x), gender_direction) \\\n",
    "                               for x in male_stereotyped_prof if x in E.words}\n",
    "    neutral_gender = {x: np.dot(E.v(x), gender_direction)  \\\n",
    "                      for x in neutral_prof if x in E.words}\n",
    "    female_p = list(female_stereotyped_gender.keys())\n",
    "    male_p = list(male_stereotyped_gender.keys())\n",
    "    neutral_p = list(neutral_gender.keys())\n",
    "    y_female = {female_p[x]:x/(len(female_p)) for x in range(len(female_p))}\n",
    "    y_male = {male_p[x]:x/(len(male_p)) for x in range(len(male_p))}\n",
    "    y_neutral = {neutral_p[x]:x/(len(neutral_p)) for x in range(len(neutral_p))}\n",
    "    fig = plt.figure()\n",
    "    fig.set_size_inches(8, 6)\n",
    "    f, = plt.plot(list(female_stereotyped_gender.values()), list(y_female.values()), 'ro', label = 'Female')\n",
    "    m, = plt.plot(list(male_stereotyped_gender.values()), list(y_male.values()), 'ko', label = 'Male')\n",
    "    n, = plt.plot(list(neutral_gender.values()), list(y_neutral.values()), 'bx', label = 'Neutral')\n",
    "    \n",
    "    plotx = [neutral_gender[x] for x in n_to_plot if x in neutral_gender]\n",
    "    ploty = [y_neutral[x] for x in n_to_plot if x in neutral_gender] \n",
    "    plt.plot(plotx, ploty, 'gx', markersize=10)\n",
    "\n",
    "    plt.yticks([])\n",
    "    # plt.legend(handles=[f,m,n], loc='best', fontsize = 15)\n",
    "\n",
    "    for x in female_stereotyped_gender:\n",
    "        x_l = female_stereotyped_gender[x] \n",
    "        y_l = y_female[x]\n",
    "        plt.annotate(x, (x_l, y_l ), fontsize=15)\n",
    "\n",
    "    for x in m_to_plot[:]:\n",
    "        ann_x = male_stereotyped_gender[x]\n",
    "        plt.annotate(x, (ann_x, y_male[x]), fontsize=15)\n",
    "    \n",
    "    for x in n_to_plot:\n",
    "        if x not in neutral_gender:\n",
    "            continue\n",
    "        x_l = neutral_gender[x]\n",
    "        y_l = y_neutral[x] \n",
    "        plt.annotate(x, (x_l, y_l ), fontsize = 15)\n",
    "    plt.xticks(fontsize=17)\n",
    "    plt.title(f\"Bias analysis in {ll}\")\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "occupation_files = '/tmp/t-jizhao/debiaswe/data/professions.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_professions(occupation_files = occupation_files):\n",
    "    with open(occupation_files, 'r') as f:\n",
    "        professions = json.load(f)\n",
    "    print('Loaded professions\\n' +\n",
    "          'Format:\\n' +\n",
    "          'word,\\n' +\n",
    "          'definitional female -1.0 -> definitional male 1.0\\n' +\n",
    "          'stereotypical female -1.0 -> stereotypical male 1.0')\n",
    "    return professions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded professions\n",
      "Format:\n",
      "word,\n",
      "definitional female -1.0 -> definitional male 1.0\n",
      "stereotypical female -1.0 -> stereotypical male 1.0\n",
      "320\n",
      "[['alter_ego', 0.0, 0.0], ['ambassador', 0.0, 0.7], ['analyst', 0.0, 0.4], ['anthropologist', 0.0, 0.4], ['archaeologist', 0.0, 0.6], ['archbishop', 0.4, 0.5], ['architect', 0.1, 0.6], ['artist', 0.0, -0.2], ['artiste', -0.1, -0.2], ['assassin', 0.1, 0.8], ['assistant_professor', 0.1, 0.4], ['associate_dean', 0.0, 0.4], ['associate_professor', 0.0, 0.4], ['astronaut', 0.1, 0.8], ['astronomer', 0.1, 0.5], ['athlete', 0.0, 0.7], ['athletic_director', 0.1, 0.7], ['attorney', 0.0, 0.3], ['author', 0.0, 0.1], ['baker', 0.0, -0.1]]\n"
     ]
    }
   ],
   "source": [
    "professions_raw = load_professions()\n",
    "print(len(professions_raw))\n",
    "print(professions_raw[10:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_bias(en_ori_E, en_ori_gd, 'ori EN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_bias(en_ali_E, en_ali_gd, 'aligned EN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_bias(en_mul_E, -en_mul_gd, 'multi EN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_m_to_plot = [en2es[x][0] for x in m_to_plot if en2es[x] != []]\n",
    "es_n_to_plot = ['enfermera', 'enfermero', 'casero', 'alguacil', 'presidente', 'coronel', 'cabeza', 'editorial', 'escucha' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_bias(es_ori_E, es_ori_gd, 'ori ES', es_m_to_plot, es_n_to_plot, \\\n",
    "          es_female_stereotyped_prof, es_male_stereotyped_prof, es_neutral_prof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_bias(es_mul_E, es_mul_gd, 'mul ES', es_m_to_plot, es_n_to_plot, \\\n",
    "          es_female_stereotyped_prof, es_male_stereotyped_prof, es_neutral_prof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_bias(es_ali_E, -es_ali_gd, 'aligned ES', es_m_to_plot, es_n_to_plot, \\\n",
    "          es_female_stereotyped_prof, es_male_stereotyped_prof, es_neutral_prof)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build a classifier\n",
    "- Train a classifier on EN gender def; evaluated on aligned ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_y(E, female_def, male_def):\n",
    "    X_en_f = np.array([E.v(x) for x in female_def if x in E.words])\n",
    "    X_en_m = np.array([E.v(x) for x in male_def if x in E.words])\n",
    "    y_en = np.array([1] * len(X_en_f) + [0] * len(X_en_m))\n",
    "    X_en = np.concatenate((X_en_f, X_en_m), axis = 0)\n",
    "    print(len(X_en_f), len(X_en_m))\n",
    "    return X_en, y_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_en, y_en = get_X_y(en_ori_E, female_def, male_def)\n",
    "X_es, y_es = get_X_y(es_ori_E, es_female_def, es_male_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'kernel':('linear', 'rbf'), 'C':[0.1, 1, 10]}\n",
    "svc = SVC(gamma='scale')\n",
    "clf = GridSearchCV(svc, parameters, cv=5)\n",
    "clf.fit(X_en, y_en) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_score_, clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(clf.predict(X_en), y_en))\n",
    "confusion_matrix(clf.predict(X_en), y_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_file = '/home/t-jizhao/Github/fasttext/glove.vec.txt'\n",
    "glove_en = we.WordEmbedding(glove_file)\n",
    "X_en_g, y_en_g = get_X_y(glove_en, female_def, male_def)\n",
    "clf = SVC(kernel = 'linear')\n",
    "clf.fit(X_en_g, y_en_g) \n",
    "print(accuracy_score(clf.predict(X_en_g), y_en_g))\n",
    "confusion_matrix(clf.predict(X_en_g), y_en_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on EN-biased\n",
    "female_biased_en = [x for x in neutral_prof \\\n",
    "                    if np.dot(en_ori_E.v(x), en_ori_E.v('he')) \\\n",
    "                    < np.dot(en_ori_E.v(x), en_ori_E.v('she'))]\n",
    "male_biased_en = [x for x in neutral_prof \\\n",
    "                    if np.dot(en_ori_E.v(x), en_ori_E.v('he')) \\\n",
    "                    > np.dot(en_ori_E.v(x), en_ori_E.v('she'))]\n",
    "X_bias_en, y_bias_en = get_X_y(en_ori_E, female_biased_en, male_biased_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf.score(X_bias_en, y_bias_en))\n",
    "confusion_matrix(clf.predict(X_bias_en), y_bias_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.average([np.dot(en_ori_E.v(x), en_ori_gd) \\\n",
    "            for x in female_biased_en]),\\\n",
    "np.average([np.dot(en_ori_E.v(x), en_ori_gd)\\\n",
    "            for x in male_biased_en])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#directly on ES\n",
    "clf.score(X_es, y_es)\n",
    "confusion_matrix(clf.predict(X_es), y_es)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Train classifier on ES gender def; evaluate on gender biased\n",
    "    - using original ES embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_es = SVC(kernel = 'linear')\n",
    "clf_es.fit(X_es, y_es) \n",
    "clf_es.score(X_es, y_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_neutral_es, y_neutral_es = get_X_y(es_ori_E, es_neutral_f, es_neutral_m)\n",
    "print(X_neutral_es.shape, y_neutral_es.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf_es.score(X_neutral_es, y_neutral_es))\n",
    "confusion_matrix(clf_es.predict(X_neutral_es), y_neutral_es)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - using multi ES embeddings (Orthogonal Procrustes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_es_multi, y_es_multi = get_X_y(es_mul_E, es_female_def, es_male_def)\n",
    "clf_es_mul = SVC(kernel = 'linear')\n",
    "clf_es_mul.fit(X_es_multi, y_es_multi) \n",
    "print(clf_es_mul.score(X_es_multi, y_es_multi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_neutral_es_mul, y_neutral_es_mul = get_X_y(es_mul_E, es_neutral_f, es_neutral_m)\n",
    "print(clf_es_mul.score(X_neutral_es_mul, y_neutral_es_mul))\n",
    "confusion_matrix(clf_es_mul.predict(X_neutral_es_mul), y_neutral_es_mul)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- using aligned ES embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_es_ali, y_es_ali = get_X_y(es_ali_E, es_female_def, es_male_def)\n",
    "clf_es_ali = SVC(kernel = 'linear')\n",
    "clf_es_ali.fit(X_es_ali, y_es_ali) \n",
    "print(clf_es_ali.score(X_es_ali, y_es_ali))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_neutral_es_ali, y_neutral_es_ali = get_X_y(es_ali_E, es_neutral_f, es_neutral_m)\n",
    "print(clf_es_ali.score(X_neutral_es_ali, y_neutral_es_ali))\n",
    "confusion_matrix(clf_es_ali.predict(X_neutral_es_ali), y_neutral_es_ali)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bias_proj(E, gender_direction, ll, \\\n",
    "                  es_neutral_m, es_neutral_f):\n",
    "    female_stereotyped_gender = {x: np.dot(E.v(x), gender_direction) \\\n",
    "                                 for x in es_neutral_f if x in E.words}\n",
    "    male_stereotyped_gender = {x: np.dot(E.v(x), gender_direction) \\\n",
    "                               for x in es_neutral_m if x in E.words}\n",
    "    \n",
    "    female_p = list(female_stereotyped_gender.keys())\n",
    "    male_p = list(male_stereotyped_gender.keys())\n",
    "    \n",
    "    y_female = {female_p[x]:x/(len(female_p)) for x in range(len(female_p))}\n",
    "    y_male = {male_p[x]:x/(len(male_p)) for x in range(len(male_p))}\n",
    "    fig = plt.figure()\n",
    "    fig.set_size_inches(8, 6)\n",
    "    \n",
    "    f, = plt.plot(list(female_stereotyped_gender.values()), \\\n",
    "                  list(y_female.values()), 'ro', label = 'Female Biased')\n",
    "    m, = plt.plot(list(male_stereotyped_gender.values()), \\\n",
    "                  list(y_male.values()), 'ko', label = 'Male Biased')\n",
    "    \n",
    "    plt.yticks([])\n",
    "    \n",
    "    to_anno = random.sample(range(len(female_p)), 8)\n",
    "    for x in to_anno:\n",
    "        x_l = female_stereotyped_gender[female_p[x]] \n",
    "        y_l = y_female[female_p[x]]\n",
    "        plt.annotate(female_p[x], (x_l, y_l ), fontsize=15)\n",
    "\n",
    "    for x in to_anno:\n",
    "        ann_x = male_stereotyped_gender[male_p[x]]\n",
    "        plt.annotate(male_p[x], (ann_x, y_male[male_p[x]]), fontsize=15)\n",
    "    \n",
    "    plt.xticks(fontsize=17)\n",
    "    plt.title(f\"Biased proj in {ll}\")\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bias_proj(es_ori_E, es_ori_gd, 'ori ES', es_neutral_m, es_neutral_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bias_proj(es_ali_E, -es_ali_gd, 'aligned ES', es_neutral_m, es_neutral_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# follow EN bias, what is the bias score for F-biased words and M-biased words\n",
    "#F_biased + M_biased != len(es_single_lexo)\n",
    "def cal_es_singleton_bias(E):\n",
    "    O, F, M = [], [], []\n",
    "    for f,m in es_gender_pairs:\n",
    "        overall_bias = np.average([abs(dis(E, es_single_lexo[x], f) - \\\n",
    "                                       dis(E, es_single_lexo[x], m)) \\\n",
    "                                   for x in es_single_lexo])\n",
    "        F_bias = np.average([abs(dis(E, es_single_lexo[x], f) - \\\n",
    "                                       dis(E, es_single_lexo[x], m)) \\\n",
    "                                   for x in en_biased_f])\n",
    "        M_bias = np.average([abs(dis(E, es_single_lexo[x], f) - \\\n",
    "                                       dis(E, es_single_lexo[x], m)) \\\n",
    "                                   for x in en_biased_m])\n",
    "        O.append(overall_bias)\n",
    "        F.append(F_bias)\n",
    "        M.append(M_bias)\n",
    "    return np.average(O), np.average(F), np.average(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias analysis using single-format professions lexicons\n",
      "in original ES, average bias:0.03957142403605304, avg F_bias:0.03460703590125949, avg M_bias:0.0415010569749377\n",
      "in sup-aligned ES, average bias:0.039571438976242365, avg F_bias:0.034607051940703834, avg M_bias:0.04150107266785084\n",
      "in un-aligned ES, average bias:0.05585759617176103, avg F_bias:0.04485674078912578, avg M_bias:0.060115123595827616\n"
     ]
    }
   ],
   "source": [
    "print(\"Bias analysis using single-format professions lexicons\")\n",
    "overall_bias, F_bias, M_bias = cal_bias(es_ori_E)\n",
    "print(f\"in original ES, average bias:{overall_bias}, avg F_bias:{F_bias}, avg M_bias:{M_bias}\")\n",
    "overall_bias, F_bias, M_bias = cal_bias(es_mul_E)\n",
    "print(f\"in sup-aligned ES, average bias:{overall_bias}, avg F_bias:{F_bias}, avg M_bias:{M_bias}\")\n",
    "overall_bias, F_bias, M_bias = cal_bias(es_ali_E)\n",
    "print(f\"in un-aligned ES, average bias:{overall_bias}, avg F_bias:{F_bias}, avg M_bias:{M_bias}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ##  Bias analysis using verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_verbs = []\n",
    "with open('fasttext/es_verbs.csv', 'r') as f:\n",
    "    count = 0\n",
    "    for line in f:\n",
    "        tokens = line.strip().split(',')\n",
    "        es_verbs.append(tokens[1].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori, ali = [], []\n",
    "for f, m in es_gender_pairs:\n",
    "    O_ori = np.average([abs(dis(es_ori_E, x, m) - \\\n",
    "                                       dis(es_ori_E, x, f)) \\\n",
    "                                   for x in es_verbs])\n",
    "    O_ali = np.average([abs(dis(es_ali_E, x, m) - \\\n",
    "                                       dis(es_ali_E, x, f)) \\\n",
    "                                   for x in es_verbs])\n",
    "    ori.append(O_ori), ali.append(O_ali)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias on ES verbs before aligment: 0.02664801837893686, after_alignment: 0.026637466510928114\n"
     ]
    }
   ],
   "source": [
    "print(f\"Bias on ES verbs before aligment: {np.average(ori)}, after_alignment: {np.average(ali)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json.dump(es_gender_pairs, open('fasttext/es_gender_pairs.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# female_def_professions_raw = [x for x in professions_raw if x[0] in female_def]\n",
    "# male_def_professions_raw = [x for x in professions_raw if x[0] in male_def ]\n",
    "# neutral_professions_raw = [x for x in professions_raw if (x not in female_def_professions_raw and\n",
    "#                            x not in male_def_professions_raw)]\n",
    "# female_def_prof = [x[0] for x in female_def_professions_raw \\\n",
    "#                            if x[0].lower() in vocab]\n",
    "# male_def_prof = [x[0] for x in male_def_professions_raw \\\n",
    "#                          if x[0].lower() in vocab]\n",
    "# neutral_prof = [x[0] for x in neutral_professions_raw \\\n",
    "#                 if x[0].lower() in vocab]\n",
    "# print(len(female_def_prof))\n",
    "# print(len(male_def_prof))\n",
    "# print(len(neutral_prof))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Bias with sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "pleasant = [x.strip()  for x in open('pleasant.txt', 'r').readlines()]\n",
    "unpleasant = [x.strip()  for x in open('unpleasant.txt', 'r').readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 25\n"
     ]
    }
   ],
   "source": [
    "es_pleasant = [en2es[x][0] for x in pleasant]\n",
    "es_unpleasant = [en2es[x][0] for x in unpleasant if en2es[x] != []]\n",
    "print(len(es_pleasant), len(es_unpleasant))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bias_diff(ori_E, ali_E, words, gender_def_pairs):\n",
    "    ori, ali = [], []\n",
    "    for f, m in gender_def_pairs:\n",
    "        O_ori = np.average([abs(dis(ori_E, x, m) - \\\n",
    "                                           dis(ori_E, x, f)) \\\n",
    "                                       for x in words])\n",
    "        O_ali = np.average([abs(dis(ali_E, x, m) - \\\n",
    "                                           dis(ali_E, x, f)) \\\n",
    "                                       for x in words])\n",
    "        ori.append(O_ori), ali.append(O_ali)\n",
    "    print(f\"Bias on words before aligment: {np.average(ori)}, after_alignment: {np.average(ali)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In EN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias on words before aligment: 0.04284609885513783, after_alignment: 0.04284764948487282\n",
      "Bias on words before aligment: 0.03575442790985107, after_alignment: 0.03575175215303898\n"
     ]
    }
   ],
   "source": [
    "get_bias_diff(en_ori_E, en_ali_E, pleasant, gender_pairs)\n",
    "get_bias_diff(en_ori_E, en_ali_E, unpleasant, gender_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias on words before aligment: 0.03740838485956192, after_alignment: 0.03740838485956192\n",
      "Bias on words before aligment: 0.03146131804585457, after_alignment: 0.03146131804585457\n"
     ]
    }
   ],
   "source": [
    "get_bias_diff(en_sup_E, en_sup_E, pleasant, gender_pairs)\n",
    "get_bias_diff(en_sup_E, en_sup_E, unpleasant, gender_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias on words before aligment: 0.02887786931461758, after_alignment: 0.02887786931461758\n"
     ]
    }
   ],
   "source": [
    "get_bias_diff(es_ori_E, es_sup_E, es_pleasant, es_gender_pairs)\n",
    "get_bias_diff(es_ori_E, es_sup_E, es_unpleasant, es_gender_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias on words before aligment: 0.033097195294168255, after_alignment: 0.033097195294168255\n",
      "Bias on words before aligment: 0.028620654675695634, after_alignment: 0.028620654675695634\n"
     ]
    }
   ],
   "source": [
    "get_bias_diff(es_sup_E, es_sup_E, es_pleasant, es_gender_pairs)\n",
    "get_bias_diff(es_sup_E, es_sup_E, es_unpleasant, es_gender_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# en_neutral_score = {x[0]:[x[1], x[2]] for x in neutral_professions_raw}\n",
    "# en_biased_m = [x for x in en_neutral_score if float(en_neutral_score[x][1]) > 0]\n",
    "# en_biased_f = [x for x in en_neutral_score if float(en_neutral_score[x][1]) < -0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in original EN, average bias:0.04776176616868556, avg F_bias:0.7566125864966737, avg M_bias:0.7455528793277875\n"
     ]
    }
   ],
   "source": [
    "# O, F, M = cal_bias_paired(en_ori_E, neutral_prof, neutral_prof, neutral_prof, gender_pairs)\n",
    "# print(f\"in original EN, average bias:{O}, avg F_bias:{F}, avg M_bias:{M}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In algined EN, average bias:0.040779857862464804, avg F_bias:0.6958112337812782, avg M_bias:0.6892272675747948\n"
     ]
    }
   ],
   "source": [
    "# O, F, M = cal_bias_paired(en_sup_fr_E, neutral_prof, neutral_prof, neutral_prof, gender_pairs)\n",
    "# print(f\"In algined EN, average bias:{O}, avg F_bias:{F}, avg M_bias:{M}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In algined EN, average bias:0.0503315428418918, avg F_bias:0.7809175156299197, avg M_bias:0.7663548305408632\n"
     ]
    }
   ],
   "source": [
    "# O, F, M = cal_bias_paired(en_sup_zh_E, neutral_prof, neutral_prof, neutral_prof, gender_pairs)\n",
    "# print(f\"In algined EN, average bias:{O}, avg F_bias:{F}, avg M_bias:{M}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 16 242\n"
     ]
    }
   ],
   "source": [
    "# es_female_stereotyped_prof = [en2es[x][0] for x in female_def_prof if en2es[x] != []]\n",
    "# es_male_stereotyped_prof = [en2es[x][0] for x in male_def_prof if en2es[x] != []]\n",
    "# es_neutral_prof = [en2es[x][0] for x in neutral_prof if en2es[x] != []]\n",
    "# print(len(es_female_stereotyped_prof), len(es_male_stereotyped_prof), len(es_neutral_prof))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# es_female_def, es_male_def = [], []\n",
    "# for x in female_def:\n",
    "#     if x in en2es:\n",
    "#         if len(en2es[x]) > 1:\n",
    "#             for t in en2es[x]:\n",
    "#                 if t[-1] == 'a' or t[-2:] == 'as':\n",
    "#                     es_female_def.append(t)\n",
    "#                     break\n",
    "#         else:\n",
    "#             es_female_def.append(x)\n",
    "# for x in male_def:\n",
    "#     if x in en2es:\n",
    "#         if len(en2es[x]) > 1:\n",
    "#             for t in en2es[x]:\n",
    "#                 if t[-1] == 'o' or t[-2:] == 'os':\n",
    "#                     es_male_def.append(t)\n",
    "#                     break \n",
    "#         else:\n",
    "#             es_male_def.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# es_female_def[:3], es_male_def[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126 126\n"
     ]
    }
   ],
   "source": [
    "# es_neutral_profs = [en2es[x] for x in neutral_prof if len(en2es[x]) > 1]\n",
    "# es_neutral_profs_en = [x for x in neutral_prof if len(en2es[x]) > 1]\n",
    "# print(len(es_neutral_profs), len(es_neutral_profs_en))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87 87 87\n"
     ]
    }
   ],
   "source": [
    "# es_neutral_f, es_neutral_m = [], []\n",
    "# es_neutral_en = []\n",
    "# ignored = []\n",
    "# for x in range(len(es_neutral_profs)):\n",
    "#     flag = 0\n",
    "#     tmp = ['', '']\n",
    "#     for t in es_neutral_profs[x]:\n",
    "#         if t.endswith('a'):\n",
    "#             tmp[0] = t\n",
    "#         else:\n",
    "#             tmp[1] = t\n",
    "#         if tmp[0] != '' and tmp[1] != '':\n",
    "#             es_neutral_f.append(tmp[0])\n",
    "#             es_neutral_m.append(tmp[1])\n",
    "#             flag = 1\n",
    "#             es_neutral_en.append(es_neutral_profs_en[x])\n",
    "#             break\n",
    "#     if flag == 0:\n",
    "#         ignored.append(es_neutral_profs[x])\n",
    "# print(len(es_neutral_f), len(es_neutral_m), len(es_neutral_en))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cos_sim between occ and gender word (feminine prof, 'ella') - (masculine prof, 'el')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_bias_proj(E, gd, es_neutral_m, es_neutral_f):\n",
    "    female_biased_es = [es_neutral_f[x] for x in range(len(es_neutral_f)) \\\n",
    "                        if np.dot(E.v(es_neutral_m[x]), E.v('macho')) \\\n",
    "                        < np.dot(E.v(es_neutral_f[x]), E.v('femenino'))]\n",
    "    male_biased_es = [es_neutral_m[x] for x in range(len(es_neutral_m)) \\\n",
    "                        if np.dot(E.v(es_neutral_m[x]), E.v('macho')) \\\n",
    "                        > np.dot(E.v(es_neutral_f[x]), E.v('femenino'))]\n",
    "    print(f\"len(male/female_biased_es prof): {len(male_biased_es), len(female_biased_es)}\")\n",
    "    print(male_biased_es[:3], female_biased_es[:3])\n",
    "    print(\"male-biased occupations projected on gender direction:\", \\\n",
    "          np.average([np.dot(E.v(x), gd) for x in male_biased_es]))\n",
    "    print(\"female-biased occupations projected on gender direction:\", \\\n",
    "          np.average([np.dot(E.v(x), gd) for x in female_biased_es]))\n",
    "    return female_biased_es, male_biased_es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(male/female_biased_es prof): (23, 64)\n",
      "['aventurero', 'asesino', 'locutor'] ['administradora', 'embajadora', 'analista']\n",
      "male-biased occupations projected on gender direction: 0.08865328\n",
      "female-biased occupations projected on gender direction: -0.2283584\n"
     ]
    }
   ],
   "source": [
    "female_biased_es, male_biased_es = show_bias_proj(es_ori_E, es_ori_gd, es_neutral_m, es_neutral_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(male/female_biased_es prof): (19, 68)\n",
      "['asesino', 'locutor', 'carnicero'] ['administradora', 'aventurera', 'embajadora']\n",
      "male-biased occupations projected on gender direction: -0.019205257\n",
      "female-biased occupations projected on gender direction: 0.2831623\n"
     ]
    }
   ],
   "source": [
    "female_biased_es_ali, male_biased_es_ali = \\\n",
    "show_bias_proj(es_ali_E, es_ali_gd, es_neutral_m, es_neutral_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(male/female_biased_es prof): (26, 61)\n",
      "['aventurero', 'asesino', 'locutor'] ['administradora', 'embajadora', 'analista']\n",
      "male-biased occupations projected on gender direction: 0.035033684\n",
      "female-biased occupations projected on gender direction: 0.27913365\n"
     ]
    }
   ],
   "source": [
    "_, _ = show_bias_proj(es_sup_E, es_sup_gd, es_neutral_m, es_neutral_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'caricaturista', 'ministra', 'policía'},\n",
       " {'aventurera',\n",
       "  'dentista',\n",
       "  'diplomática',\n",
       "  'enviada',\n",
       "  'mecánica',\n",
       "  'peluquera',\n",
       "  'secretaría'})"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(female_biased_es) - set(female_biased_es_ali), \\\n",
    "set(female_biased_es_ali) - set(female_biased_es)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### 2.1 Single format for masculine and feminine occupations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# es_single_lexo = {x:en2es[x][0] for x in neutral_prof if len(en2es[x]) == 1}\n",
    "# es_single_lexo\n",
    "# len(es_single_lexo), es_single_lexo['alderman']\n",
    "# print(len(en_biased_f), len(en_biased_m))\n",
    "# en_neutral_score['caretaker']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumption:\n",
    "- Assume the original points in the gender direction means gender neutral \n",
    "- Assume all these occupations should have same distance to male/female\n",
    "- Diff(dis_to_he, dis_to_she)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- #### 2.2 Bias analysis with two-format occupations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# es_gender_pairs = [['mujer', 'hombre'], ['chica', 'chico'], ['madre', 'padre'], ['hija', 'hijo'],\n",
    "#                   ['femenino', 'masculino'], ['su', 'su'], ['maría', 'juan'], ['hembra', 'macho'],\n",
    "#                   ['ella', 'él']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in original ES, average bias:0.07259895407748176, avg F_bias:0.7321097015535237, avg M_bias:0.7776997056819432\n"
     ]
    }
   ],
   "source": [
    "#for paired occupations in ES\n",
    "o, F, M = cal_bias_paired(es_ori_E, es_neutral_m, es_neutral_f, es_neutral_en, es_gender_pairs)\n",
    "print(f\"in original ES, average bias:{o}, avg F_bias:{F}, avg M_bias:{M}\")\n",
    "o, F, M = cal_bias_paired(es_ali_E, es_neutral_m, es_neutral_f, es_neutral_en, es_gender_pairs)\n",
    "print(f\"in en-aligned ES, average bias:{o}, avg F_bias:{F}, avg M_bias:{M}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for both singleton + paired occs in ES:\n",
    "xm = es_neutral_m #+ [es_single_lexo[x] for x in es_single_lexo]\n",
    "xf = es_neutral_f #+ [es_single_lexo[x] for x in es_single_lexo]\n",
    "es_en = es_neutral_en #+ [x for x in es_single_lexo]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias in DE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "en2de = defaultdict(list)\n",
    "with open('/tmp/t-jizhao/data/fasttext/en-de.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        en, de = line.strip().split()\n",
    "        en2de[en].append(de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m_ind = \"-er, -el, -ling, -ich, -ig, -ner, -ismus, -or, -us, -eich, -ant\"\n",
    "# f_ind = \"-e, -ie, -heit, -ei, -in, -ik, -keit, – schaft, -ung, -tät, -ur, -tion\"\n",
    "# n_ind = \"-chen, -o, -lein, -en, -il, -ma, -tel, -ment, -nis, -tum, -um\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# de_mks, de_fks, de_nks = [], [], []\n",
    "# for mi in m_ind.strip().split(', '):\n",
    "#     de_mks.append(mi[1:])\n",
    "\n",
    "# for fi in f_ind.strip().split(', '):\n",
    "#     de_fks.append(fi[1:])\n",
    "    \n",
    "# for ni in n_ind.strip().split(', '):\n",
    "#     de_nks.append(ni[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# de_profs = {}\n",
    "# de_single_profs = {}\n",
    "# for x in neutral_prof:\n",
    "    \n",
    "#     if len(en2de[x]) == 1:\n",
    "#         de_single_profs[x] = en2de[x][0]\n",
    "#         continue\n",
    "#     tmp = ['', '', '']\n",
    "#     for t in en2de[x]:\n",
    "#         for i in de_mks:\n",
    "#             if t.endswith(i):\n",
    "#                 tmp[0] = t\n",
    "#                 break\n",
    "#         for i in de_fks:\n",
    "#             if t.endswith(i):\n",
    "#                 tmp[1] = t\n",
    "#                 break\n",
    "#         for i in de_nks:\n",
    "#             if t.endswith(i):\n",
    "#                 tmp[2] = t\n",
    "#                 break\n",
    "#         if tmp[0] != '' and tmp[1] != '':\n",
    "#             de_profs[x] = tmp[:]\n",
    "#             break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# de_prof_m = [de_profs[x][0] for x in de_profs] + [de_single_profs[x] for x in de_single_profs]\n",
    "# de_prof_f = [de_profs[x][1] for x in de_profs] + [de_single_profs[x] for x in de_single_profs]\n",
    "# de_prof_en = [x for x in de_profs] + [x for x in de_single_profs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# de_gender_def_pairs = []\n",
    "# for f,m in gender_pairs:\n",
    "#     if en2de[f.lower()] != [] and en2de[m.lower()] != []:\n",
    "#         de_gender_def_pairs.append([en2de[f.lower()][0], en2de[m.lower()][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 25\n"
     ]
    }
   ],
   "source": [
    "de_pleasant = [en2de[x][0] for x in pleasant if en2de[x] != []]\n",
    "de_unpleasant = [en2de[x][0] for x in unpleasant if en2de[x] != []]\n",
    "print(len(de_pleasant), len(de_unpleasant))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias in sentiment words\n",
      "---pleasant words:\n",
      "Bias on words before aligment: 0.047716377211941614, after_alignment: 0.05466125662955973\n",
      "---unpleasant words:\n",
      "Bias on words before aligment: 0.04536173863543405, after_alignment: 0.049679737471871904\n"
     ]
    }
   ],
   "source": [
    "print(\"Bias in sentiment words\")\n",
    "print(\"---pleasant words:\")\n",
    "get_bias_diff(de_ori_E, de_ali_E, de_pleasant, de_gender_pairs)\n",
    "print(\"---unpleasant words:\")\n",
    "get_bias_diff(de_ori_E, de_ali_E, de_unpleasant, de_gender_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias in sentiment words\n",
      "---pleasant words:\n",
      "Bias on words before aligment: 0.04487085190084246, after_alignment: 0.04487085190084246\n",
      "---unpleasant words:\n",
      "Bias on words before aligment: 0.0416201490826077, after_alignment: 0.0416201490826077\n"
     ]
    }
   ],
   "source": [
    "print(\"Bias in sentiment words\")\n",
    "print(\"---pleasant words:\")\n",
    "get_bias_diff(de_sup_E, de_sup_E, de_pleasant, de_gender_pairs)\n",
    "print(\"---unpleasant words:\")\n",
    "get_bias_diff(de_sup_E, de_sup_E, de_unpleasant, de_gender_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "metadata": {},
   "outputs": [],
   "source": [
    "# width = 15\n",
    "# with open('fasttext/pleasants.txt', 'w') as f:\n",
    "#     f.write('{: <{}}'.format('EN', width) + '{: <{}}'.format('ES', width) + \\\n",
    "#             '{: <{}}'.format('DE', width) +  '{: <{}}'.format('FR', width)+ '\\n')\n",
    "#     for idx in range(len(pleasant)):\n",
    "#         f.write('{: <{}}'.format(pleasant[idx], width) + '{: <{}}'.format(es_pleasant[idx], width) + \\\n",
    "#             '{: <{}}'.format(de_pleasant[idx], width) + '{: <{}}'.format(fr_pleasant[idx], width) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias in FR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "en2fr = defaultdict(list)\n",
    "with open('/home/t-jizhao/Github/data/fasttext/en-fr.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        en, fr = line.strip().split()\n",
    "        en2fr[en].append(fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_ind = \"-age, -ment, -il, -ail, -eil, -euil, -é, -eau, -eu, -er, -oir, -isme, -ing, -ard, -am, -um, -em, -it, -est, -an, -and, -ant, -ent, -in, -int, -om, -ond, -ont, -ème, -ège\"\n",
    "f_ind = \"-tion, -sion, -son, -ure, -ude, -ade, -ée, -té, -ière, -euse, -ance, -ence, -ine, -elle, -esse, -ette\"\n",
    "mks, fks, nks = [], [], []\n",
    "for mi in m_ind.strip().split(', '):\n",
    "    mks.append(mi[1:])\n",
    "\n",
    "for fi in f_ind.strip().split(', '):\n",
    "    fks.append(fi[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_profs = {}\n",
    "fr_single_profs = {}\n",
    "for x in neutral_prof:\n",
    "    if len(en2fr[x])  == 1:\n",
    "        fr_single_profs[x] = en2fr[x][0]\n",
    "        continue\n",
    "    tmp = ['', '', '']\n",
    "    for t in en2fr[x]:\n",
    "        for i in mks:\n",
    "            if t.endswith(i):\n",
    "                tmp[0] = t\n",
    "                break\n",
    "        for i in fks:\n",
    "            if t.endswith(i):\n",
    "                tmp[1] = t\n",
    "                break\n",
    "        if tmp[0] != '' and tmp[1] != '':\n",
    "            fr_profs[x] = tmp[:2]\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(117, 10)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fr_single_profs), len(fr_profs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "rx = re.compile('([\\'\\[,\\]])')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_profs = {}\n",
    "with open('fr2plot.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        line = rx.sub('', line.strip())\n",
    "        tokens = line.strip().split()\n",
    "        if len(tokens) == 2:\n",
    "            tokens.append(tokens[-1])\n",
    "        fr_profs[tokens[0]]= tokens[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fr_gender_def_pairs = []\n",
    "# for f,m in gender_pairs:\n",
    "#     if en2fr[f.lower()] != [] and en2fr[m.lower()] != []:\n",
    "#         fr_gender_def_pairs.append([en2fr[f.lower()][0], en2fr[m.lower()][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json.dump(fr_gender_pairs, open('fasttext/fr_gender_pairs.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 25\n"
     ]
    }
   ],
   "source": [
    "fr_pleasant = [en2fr[x][0] for x in pleasant if en2fr[x] != []]\n",
    "fr_unpleasant = [en2fr[x][0] for x in unpleasant if en2fr[x] != []]\n",
    "print(len(fr_pleasant), len(fr_unpleasant))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vacation']"
      ]
     },
     "execution_count": 849,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in pleasant if en2fr[x] == []]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias in sentiment words\n",
      "---pleasant words:\n",
      "Bias on words before aligment: 0.052481612940318875, after_alignment: 0.0626819814601913\n",
      "---unpleasant words:\n",
      "Bias on words before aligment: 0.059130257647484544, after_alignment: 0.06513589754293206\n"
     ]
    }
   ],
   "source": [
    "print(\"Bias in sentiment words\")\n",
    "print(\"---pleasant words:\")\n",
    "get_bias_diff(fr_ori_E, fr_ali_E, fr_pleasant, fr_gender_pairs)\n",
    "print(\"---unpleasant words:\")\n",
    "get_bias_diff(fr_ori_E, fr_ali_E, fr_unpleasant, fr_gender_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_prof_m = [fr_profs[x][0] for x in fr_profs] + [fr_single_profs[x] for x in fr_single_profs]\n",
    "fr_prof_f = [fr_profs[x][1] for x in fr_profs] + [fr_single_profs[x] for x in fr_single_profs]\n",
    "fr_prof_en = [x for x in fr_profs] + [x for x in fr_single_profs]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
